pdf(paste0("output/OleA_JGI_tree_seqs_v8_with_Xantho_unlabeled_with_legend.pdf"), width=8, height=8)
pt +
geom_tippoint(aes(color = I(color),shape =I(shape), alpha = I(alpha), size = pt$data$size)) +
geom_nodepoint(color = "black", size = pt$data$size[!pt$data$isTip]) +
scale_size_continuous(name = "Amino acid\n identity (%)",
range = c(1,9),
breaks = c(1:8),
labels = paste0((c(1:8)) * 10, "%")) +
scale_color_manual(values = "red") +
theme(legend.position = "right",
legend.text=element_text(size=12),
panel.background = element_rect(fill = "transparent"), # or theme_blank()
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
plot.background = element_rect(fill = "transparent"))
# geom_tiplab(label = p$data$label_tr[p$data$isTip])
# geom_label_repel(label = p$data$label_tr)
#  ggplot2::xlim(2, NA)
# geom_label_repel(label = p$data$label_tr, size = 4, force = 20,
# ssegment.alpha = 0.5, segment.color = "black")
# geom_label2(label = p$data$label)
#ggplot2::xlim(0, -1)
#  geom_text2(aes(subset=grepl(paste0(all, collapse = "|"), label),label=label),size=2)
dev.off()
pt$data$size[1] <- 1
pdf(paste0("output/OleA_JGI_tree_seqs_v8_with_Xantho_unlabeled_with_legend.pdf"), width=8, height=8)
pt +
geom_tippoint(aes(color = I(color),shape =I(shape), alpha = I(alpha), size = pt$data$size)) +
geom_nodepoint(color = "black", size = pt$data$size[!pt$data$isTip]) +
scale_size_continuous(name = "Amino acid\n identity (%)",
range = c(1,9),
breaks = c(1:8),
labels = paste0((c(1:8)) * 10, "%")) +
scale_color_manual(values = "red") +
theme(legend.position = "right",
legend.text=element_text(size=12),
panel.background = element_rect(fill = "transparent"), # or theme_blank()
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
plot.background = element_rect(fill = "transparent"))
# geom_tiplab(label = p$data$label_tr[p$data$isTip])
# geom_label_repel(label = p$data$label_tr)
#  ggplot2::xlim(2, NA)
# geom_label_repel(label = p$data$label_tr, size = 4, force = 20,
# ssegment.alpha = 0.5, segment.color = "black")
# geom_label2(label = p$data$label)
#ggplot2::xlim(0, -1)
#  geom_text2(aes(subset=grepl(paste0(all, collapse = "|"), label),label=label),size=2)
dev.off()
pt$data$size[1] <- 1
pdf(paste0("output/OleA_JGI_tree_seqs_v8_with_Xantho_unlabeled_with_legend.pdf"), width=8, height=8)
pt +
geom_tippoint(aes(color = I(color),shape =I(shape), alpha = I(alpha), size = pt$data$size)) +
geom_nodepoint(color = "black", size = pt$data$size[!pt$data$isTip]) +
scale_size_continuous(name = "Amino acid\n identity (%)",
range = c(1,9),
breaks = c(1:8),
labels = paste0((c(1:8)) * 10, "%")) +
scale_color_manual(values = c("red", "red", "red")) +
theme(legend.position = "right",
legend.text=element_text(size=12),
panel.background = element_rect(fill = "transparent"), # or theme_blank()
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
plot.background = element_rect(fill = "transparent"))
# geom_tiplab(label = p$data$label_tr[p$data$isTip])
# geom_label_repel(label = p$data$label_tr)
#  ggplot2::xlim(2, NA)
# geom_label_repel(label = p$data$label_tr, size = 4, force = 20,
# ssegment.alpha = 0.5, segment.color = "black")
# geom_label2(label = p$data$label)
#ggplot2::xlim(0, -1)
#  geom_text2(aes(subset=grepl(paste0(all, collapse = "|"), label),label=label),size=2)
dev.off()
pt$data$size[1] <- 1
pdf(paste0("output/OleA_JGI_tree_seqs_v8_with_Xantho_unlabeled_with_legend.pdf"), width=8, height=8)
pt +
geom_nodepoint(color = "black", size = pt$data$size[!pt$data$isTip]) +
range = c(1,9),
pdf(paste0("output/OleA_JGI_tree_seqs_v8_with_Xantho_unlabeled_with_legend.pdf"), width=8, height=8)
pt +
geom_nodepoint(color = "black", size = pt$data$size[!pt$data$isTip]) +
range = c(1,9),
pdf(paste0("output/OleA_JGI_tree_seqs_v8_with_Xantho_unlabeled_with_legend.pdf"), width=8, height=8)
pt +
geom_nodepoint(color = "black", size = pt$data$size[!pt$data$isTip]) +
scale_color_manual(values = c("red", "red", "red") +
range = c(1,9),
pdf(paste0("output/OleA_JGI_tree_seqs_v8_with_Xantho_unlabeled_with_legend.pdf"), width=8, height=8)
pt +
geom_tippoint(aes(color = I(color),shape =I(shape), alpha = I(alpha), size = pt$data$size)) +
geom_nodepoint(color = "black", size = pt$data$size[!pt$data$isTip]) +
guides(colour = guide_legend()) +
scale_color_manual(values = c("red", "red", "red")) +
scale_size_continuous(name = "Amino acid\n identity (%)",
range = c(1,9),
breaks = c(1:8),
labels = paste0((c(1:8)) * 10, "%")) +
theme(legend.position = "right",
legend.text=element_text(size=12),
panel.background = element_rect(fill = "transparent"), # or theme_blank()
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
plot.background = element_rect(fill = "transparent"))
# geom_tiplab(label = p$data$label_tr[p$data$isTip])
# geom_label_repel(label = p$data$label_tr)
#  ggplot2::xlim(2, NA)
# geom_label_repel(label = p$data$label_tr, size = 4, force = 20,
# ssegment.alpha = 0.5, segment.color = "black")
# geom_label2(label = p$data$label)
#ggplot2::xlim(0, -1)
#  geom_text2(aes(subset=grepl(paste0(all, collapse = "|"), label),label=label),size=2)
dev.off()
pdf(paste0("output/OleA_JGI_tree_seqs_v8_with_Xantho_unlabeled_with_legend.pdf"), width=8, height=8)
pt +
geom_tippoint(aes(color = I(color),shape =I(shape), alpha = I(alpha), size = pt$data$size)) +
geom_nodepoint(color = "black", size = pt$data$size[!pt$data$isTip]) +
# guides(colour = guide_legend()) +
# scale_color_manual(values = c("red", "red", "red")) +
scale_size_continuous(name = "Amino acid\n identity (%)",
range = c(1,9),
breaks = c(1:8),
labels = paste0((c(1:8)) * 10, "%")) +
theme(legend.position = "right",
legend.text=element_text(size=12),
panel.background = element_rect(fill = "transparent"), # or theme_blank()
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
plot.background = element_rect(fill = "transparent"))
# geom_tiplab(label = p$data$label_tr[p$data$isTip])
# geom_label_repel(label = p$data$label_tr)
#  ggplot2::xlim(2, NA)
# geom_label_repel(label = p$data$label_tr, size = 4, force = 20,
# ssegment.alpha = 0.5, segment.color = "black")
# geom_label2(label = p$data$label)
#ggplot2::xlim(0, -1)
#  geom_text2(aes(subset=grepl(paste0(all, collapse = "|"), label),label=label),size=2)
dev.off()
## Install packages
pacman::p_load("caret", "data.table", "Biostrings", "phangorn", "ape", "seqinr", "DECIPHER", "cowplot", "tidymodels", "ranger", "tree", "rsample", "tidyverse", "randomForest","gbm","nnet","e1071","svmpath","lars","glmnet","svmpath")
# Set working directory
setwd("~/Documents/Wageningen_UR/github/mibig_training_set_build_test/")
# Read in the adenylpred
apred <- read_excel("data/AdenylPred-2019-04-09.xlsx")
colnames(apred)
# Read in the adenylpred
apred <- read_excel("data/AdenylPred-2019-04-09.xlsx") %>%
janitor::clean_names() %>%
mutate(truth_subspec = word(apred, sep = "_", -3)) %>%
mutate(truth_class = word(apred, sep = "_", -1))
write_excel(apred, "data/adenylpred_output_20190409.xlsx")
## Install packages
pacman::p_load("caret", "readxl", "data.table", "Biostrings", "phangorn", "ape", "seqinr", "DECIPHER", "cowplot", "tidymodels", "ranger", "tree", "rsample", "tidyverse", "randomForest","gbm","nnet","e1071","svmpath","lars","glmnet","svmpath")
write_excel(apred, "data/adenylpred_output_20190409.xlsx")
write_csv(apred, "data/adenylpred_output_20190409.csv")
# Read in the adenylpred
apred <- read_excel("data/AdenylPred-2019-04-09.xlsx") %>%
janitor::clean_names() %>%
mutate(truth_subspec = word(apred, sep = "_", -3)) %>%
mutate(truth_class = word(apred, sep = "_", -1))
colnames(apred)
# Read in the adenylpred
apred <- read_excel("data/AdenylPred-2019-04-09.xlsx") %>%
janitor::clean_names()
colnames(apred)
# Read in the adenylpred
apred <- read_excel("data/AdenylPred-2019-04-09.xlsx") %>%
janitor::clean_names() %>%
mutate(truth_subspec = word(query_name, sep = "_", -3)) %>%
mutate(truth_class = word(query_name, sep = "_", -1))
write_csv(apred, "data/adenylpred_output_20190409.csv")
669 * 60
669/60
## Install packages
pacman::p_load("caret", "readxl", "data.table", "Biostrings", "phangorn", "ape", "seqinr", "DECIPHER", "cowplot", "tidymodels", "ranger", "tree", "rsample", "tidyverse", "randomForest","gbm","nnet","e1071","svmpath","lars","glmnet","svmpath")
# Set working directory
setwd("~/Documents/Wageningen_UR/github/mibig_training_set_build_test/")
colnames(apred)
# Set working directory
setwd("~/Documents/Wageningen_UR/github/mibig_training_set_build_test/")
colnames(apred)
# Read in the adenylpred
apred <- read_excel("data/AdenylPred-2019-04-09.csv") %>%
janitor::clean_names() %>%
mutate(truth_subspec = word(query_name, sep = "_", -3)) %>%
mutate(truth_class = word(query_name, sep = "_", -1))
# Read in the adenylpred
apred <- read_csv("data/AdenylPred-2019-04-09.csv") %>%
janitor::clean_names() %>%
mutate(truth_subspec = word(query_name, sep = "_", -3)) %>%
mutate(truth_class = word(query_name, sep = "_", -1))
apred
write_csv(apred, "data/adenylpred_output_20190409.csv")
## Install packages
pacman::p_load("caret", "Biostrings", "phangorn", "ape", "seqinr", "DECIPHER", "cowplot", "tidymodels", "ranger", "tree", "rsample", "tidyverse", "randomForest","gbm","nnet","e1071","svmpath","lars","glmnet","svmpath")
# Set working directory
setwd("~/Documents/Wageningen_UR/github/mibig_training_set_build_test/")
# Convert the 713 aa signatures to features
rdaln <- read.alignment(file = 'data/1742_aa34_signatures_20190104.fa', format = "fasta")
tmp <- read.csv("data/15_aa_properties_scaled.csv", stringsAsFactors = F)
head(tmp)
tmp <- read.csv("data/15_aa_properties_scaled.csv", stringsAsFactors = F) %>%
column_to_rownames(var = AA_ABREV)
tmp <- read.csv("data/15_aa_properties_scaled.csv", stringsAsFactors = F) %>%
column_to_rownames(var = "AA_ABREV")
head(tmp)
source("src/convert_aln_15aap.r")
aa <- convert_aln_15aap(rdaln) #5 physicochemical properties
source("src/convert_aln_15aap.r")
aa <- convert_aln_15aap(rdaln) #5 physicochemical properties
aadf <- data.frame(aa,stringsAsFactors = F)
head(aadf)
# Write to CSV file
write.csv(aadf, paste0("data/1742_seqs_510_feats_scaled_20190904.csv"), row.names=rownames(aap), quote = F)
rownames(aadf)
# Write to CSV file
write.csv(aadf, paste0("data/1742_seqs_510_feats_scaled_20190904.csv"), row.names=rownames(aadf), quote = F)
# Read in the data
rawdat <- read_csv("data/1742_seqs_510_feats_scaled_20190904.csv")
rawdat <- data.frame(cbind(rawdat$X1), scale(rawdat[,2:ncol(rawdat)]), stringsAsFactors = F)
colnames(rawdat)[1] <- "nms"
rawdat$clf <- word(rawdat$nms, -3, sep = "_")
table(rawdat$clf)
# Remove the holdout test predictions
dat <- rawdat[-grep(paste0(c("HOLDOUT", "OTHER", "CAR", "amino.acid"), collapse = "|"), rawdat$nms),] # 658 observations
# Set seed
set.seed(20190304)
dat_split <- initial_split(dat, strata = "clf")
dat_train <- training(dat_split)
dat_test  <- testing(dat_split)
nrow(dat_train)/nrow(dat) # 75 %
# Define our response
x_train <- dat_train[,!colnames(dat_train) %in% c("nms", "clf")]
x_test <- dat_test[,!colnames(dat_test) %in% c("nms", "clf")]
y_train <- as.factor(dat_train$clf)
y_test <- as.factor(dat_test$clf)
table(y_test)
# Make a data frame for prediction
df_train <- data.frame(x_train, stringsAsFactors = F, row.names = dat_train$nms)
# Make a data frame for prediction
df_train <- data.frame(x_train, stringsAsFactors = F, row.names = dat_train$nms)
# Complete dataset for training and testing
form_train <- data.frame(cbind(x_train, y_train), stringsAsFactors = F, row.names = dat_train$nms)
form_test <- data.frame(cbind(x_test, y_test), stringsAsFactors = F, row.names = dat_test$nms)
rf_grid <- expand.grid(mtry = c(2, 3, 4, 5),
splitrule = c("gini", "extratrees"),
min.node.size = c(1, 3, 5))
# Tune grid for ranger
rf <- train(
x = x_train,
y = y_train,
method = "ranger",
trControl = trainControl(method = "cv", number = 10,
verboseIter = T, classProbs = T,
savePredictions = "final"),
tuneGrid = rf_grid,
num.trees = 500,
# respect.unordered.factors = FALSE,
verbose = TRUE,
importance = "permutation",
preProcess = c("center", "scale"))
sqrt(510)
rf_grid <- expand.grid(mtry = c(2, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50),
splitrule = c("gini", "extratrees"),
min.node.size = c(1, 3, 5),
max.depth = c(2, 3, 4, 5, 6, 7, 8, 9, 10))
# Tune grid for ranger
rf <- train(
x = x_train,
y = y_train,
method = "ranger",
trControl = trainControl(method = "cv", number = 10,
verboseIter = T, classProbs = T,
savePredictions = "final"),
tuneGrid = rf_grid,
num.trees = 500,
verbose = TRUE,
importance = "permutation",
preProcess = c("center", "scale"),
classification = T)
# Read in the data
rawdat <- read_csv("data/1742_seqs_510_feats_scaled_20190904.csv")
rawdat <- data.frame(cbind(rawdat$X1), scale(rawdat[,2:ncol(rawdat)]), stringsAsFactors = F)
colnames(rawdat)[1] <- "nms"
rawdat$clf <- word(rawdat$nms, -3, sep = "_")
table(rawdat$clf)
# Remove the holdout test predictions
dat <- rawdat[-grep(paste0(c("HOLDOUT", "OTHER", "CAR", "amino.acid"), collapse = "|"), rawdat$nms),] # 658 observations
# Set seed
set.seed(20190304)
dat_split <- initial_split(dat, strata = "clf")
dat_train <- training(dat_split)
dat_test  <- testing(dat_split)
nrow(dat_train)/nrow(dat) # 75 %
# Define our response
x_train <- dat_train[,!colnames(dat_train) %in% c("nms", "clf")]
x_test <- dat_test[,!colnames(dat_test) %in% c("nms", "clf")]
y_train <- as.factor(dat_train$clf)
y_test <- as.factor(dat_test$clf)
table(y_test)
# Make a data frame for prediction
df_train <- data.frame(x_train, stringsAsFactors = F, row.names = dat_train$nms)
# Complete dataset for training and testing
form_train <- data.frame(cbind(x_train, y_train), stringsAsFactors = F, row.names = dat_train$nms)
form_test <- data.frame(cbind(x_test, y_test), stringsAsFactors = F, row.names = dat_test$nms)
rf_grid <- expand.grid(mtry = c(2, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50),
splitrule = c("gini", "extratrees"),
min.node.size = c(1, 3, 5),
max.depth = c(2, 3, 4, 5, 6, 7, 8, 9, 10))
# Tune grid for ranger
rf <- train(
x = x_train,
y = y_train,
method = "ranger",
trControl = trainControl(method = "cv", number = 10,
verboseIter = T, classProbs = T,
savePredictions = "final"),
tuneGrid = rf_grid,
num.trees = 500,
verbose = TRUE,
importance = "permutation",
preProcess = c("center", "scale"),
classification = T)
## Install packages
pacman::p_load("caret", "Biostrings", "phangorn", "ape", "seqinr", "DECIPHER", "cowplot", "tidymodels", "ranger", "tree", "rsample", "tidyverse", "randomForest","gbm","nnet","e1071","svmpath","lars","glmnet","svmpath")
# Set working directory
setwd("~/Documents/Wageningen_UR/github/mibig_training_set_build_test/")
# Convert the 713 aa signatures to features
rdaln <- read.alignment(file = 'data/1742_aa34_signatures_20190104.fa', format = "fasta")
rdaln$seq <- toupper(rdaln$seq)
# Read in the data
rawdat <- read_csv("data/1742_seqs_510_feats_scaled_20190904.csv")
rawdat <- data.frame(cbind(rawdat$X1), scale(rawdat[,2:ncol(rawdat)]), stringsAsFactors = F)
colnames(rawdat)[1] <- "nms"
rawdat$clf <- word(rawdat$nms, -3, sep = "_")
table(rawdat$clf)
# Remove the holdout test predictions
dat <- rawdat[-grep(paste0(c("HOLDOUT", "OTHER", "CAR", "amino.acid"), collapse = "|"), rawdat$nms),] # 658 observations
# Set seed
set.seed(20190304)
dat_split <- initial_split(dat, strata = "clf")
dat_train <- training(dat_split)
dat_test  <- testing(dat_split)
nrow(dat_train)/nrow(dat) # 75 %
# Define our response
x_train <- dat_train[,!colnames(dat_train) %in% c("nms", "clf")]
x_test <- dat_test[,!colnames(dat_test) %in% c("nms", "clf")]
y_train <- as.factor(dat_train$clf)
y_test <- as.factor(dat_test$clf)
table(y_test)
# Make a data frame for prediction
df_train <- data.frame(x_train, stringsAsFactors = F, row.names = dat_train$nms)
# Complete dataset for training and testing
form_train <- data.frame(cbind(x_train, y_train), stringsAsFactors = F, row.names = dat_train$nms)
form_test <- data.frame(cbind(x_test, y_test), stringsAsFactors = F, row.names = dat_test$nms)
rf_grid <- expand.grid(mtry = c(2, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50),
splitrule = c("gini", "extratrees"),
min.node.size = c(1, 3, 5),
max.depth = c(2, 3, 4, 5, 6, 7, 8, 9, 10))
# Tune grid for ranger
rf <- train(
x = x_train,
y = y_train,
method = "ranger",
trControl = trainControl(method = "cv", number = 10,
verboseIter = T, classProbs = T,
savePredictions = "final"),
tuneGrid = rf_grid,
num.trees = 500,
verbose = TRUE,
importance = "permutation",
preProcess = c("center", "scale"),
classification = T)
rf_grid <- expand.grid(mtry = c(2, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50),
splitrule = c("gini", "extratrees"),
min.node.size = c(1, 3, 5))
# Tune grid for ranger
rf <- train(
x = x_train,
y = y_train,
method = "ranger",
trControl = trainControl(method = "cv", number = 10,
verboseIter = T, classProbs = T,
savePredictions = "final"),
tuneGrid = rf_grid,
num.trees = 500,
verbose = TRUE,
importance = "permutation",
preProcess = c("center", "scale"),
classification = T)
saveRDS(rf, "data/model_comparisons/rf_xvalidated_tuned_no_max_depth_20190904.rds")
saveRDS(rf, "data/20190904_model_comparisons/rf_xvalidated_tuned_no_max_depth_20190904.rds")
rf$bestTune
# Now with a max depth of 5 splits
rf5 <- train(
x = x_train,
y = y_train,
method = "ranger",
max.depth = 5,
trControl = trainControl(method = "cv", number = 10,
verboseIter = T, classProbs = T,
savePredictions = "final"),
tuneGrid = rf_grid,
num.trees = 500,
verbose = TRUE,
importance = "permutation",
preProcess = c("center", "scale"),
classification = T)
saveRDS(rf5, "data/20190904_model_comparisons/rf_xvalidated_tuned_max_depth_5_20190904.rds")
# Now with a max depth of 7 splits
rf7 <- train(
x = x_train,
y = y_train,
method = "ranger",
max.depth = 7,
trControl = trainControl(method = "cv", number = 10,
verboseIter = T, classProbs = T,
savePredictions = "final"),
tuneGrid = rf_grid,
num.trees = 500,
verbose = TRUE,
importance = "permutation",
preProcess = c("center", "scale"),
classification = T)
saveRDS(rf7, "data/20190904_model_comparisons/rf_xvalidated_tuned_max_depth_7_20190904.rds")
# Now with a max depth of 7 splits
rf3 <- train(
x = x_train,
y = y_train,
method = "ranger",
max.depth = 3,
trControl = trainControl(method = "cv", number = 10,
verboseIter = T, classProbs = T,
savePredictions = "final"),
tuneGrid = rf_grid,
num.trees = 500,
verbose = TRUE,
importance = "permutation",
preProcess = c("center", "scale"),
classification = T)
saveRDS(rf3, "data/20190904_model_comparisons/rf_xvalidated_tuned_max_depth_3_20190904.rds")
# Now with a max depth of 7 splits
rf1 <- train(
x = x_train,
y = y_train,
method = "ranger",
max.depth = 1,
trControl = trainControl(method = "cv", number = 10,
verboseIter = T, classProbs = T,
savePredictions = "final"),
tuneGrid = rf_grid,
num.trees = 500,
verbose = TRUE,
importance = "permutation",
preProcess = c("center", "scale"),
classification = T)
saveRDS(rf1, "data/20190904_model_comparisons/rf_xvalidated_tuned_max_depth_1_20190904.rds")
# Now with a max depth of 7 splits
rf9 <- train(
x = x_train,
y = y_train,
method = "ranger",
max.depth = 9,
trControl = trainControl(method = "cv", number = 10,
verboseIter = T, classProbs = T,
savePredictions = "final"),
tuneGrid = rf_grid,
num.trees = 500,
verbose = TRUE,
importance = "permutation",
preProcess = c("center", "scale"),
classification = T)
saveRDS(rf9, "data/20190904_model_comparisons/rf_xvalidated_tuned_max_depth_9_20190904.rds")
sqrt(510)
as.integer(sqrt(nrow(y_train)))
as.integer(sqrt(length(y_train)))
lengty(y_train)
as.integer(sqrt(nrow(x_train)))
nrow(x_train)
# Read in the data
rawdat <- read_csv("data/1742_seqs_510_feats_scaled_20190904.csv")
nrow(rawdat)
as.integer(sqrt(ncol(x_train)))
# Make a default model and test the effects of the number of trees on accuracy
rf_probs <- ranger(y_train ~., data = form_train, num.trees = 500, splitrule = "gini"
mtry = as.integer(sqrt(ncol(x_train))), min.node.size = 1,
importance = "permutation", probability = TRUE)
# Make a default model and test the effects of the number of trees on accuracy
rf_probs <- ranger(y_train ~., data = form_train, num.trees = 500, splitrule = "gini",
mtry = as.integer(sqrt(ncol(x_train))), min.node.size = 1,
importance = "permutation", probability = TRUE)
rf_probs
# Make a default model and test the effects of the number of trees on accuracy
rf_probs <- ranger(y_train ~., data = form_train, num.trees = 500, splitrule = "gini",
mtry = as.integer(sqrt(ncol(x_train))), min.node.size = 2,
importance = "permutation", probability = TRUE)
rf_probs
# Make a default model and test the effects of the number of trees on accuracy
rf_probs <- ranger(y_train ~., data = form_train, num.trees = 500, splitrule = "gini",
mtry = as.integer(sqrt(ncol(x_train))), min.node.size = 1,
importance = "permutation", probability = TRUE)
rf_probs
rf_probs$predictions
rf_probs_pred <- predict(rf, newdata = form_test)
rf_probs_pred[,1]
rf_probs_pred
rf_probs_pred <- predict(rf_probs, newdata = form_test)
rf_probs_pred <- predict(rf_probs, data = form_test)
rf_probs_pred
rf_probs_pred$predictions
saveRDS(rf_prob, "data/20190904_model_comparisons/rf_probability_ranger_20190904.rds")
saveRDS(rf_probs, "data/20190904_model_comparisons/rf_probability_ranger_20190904.rds")
