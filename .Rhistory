x[x > 0 & x < 10]
}
orig_mut <- names(unlist(distan))
orig_mut
df <- do.call("rbind", distan)
df2 <- data.frame(cbind(orig_mut, df))
rownames(df2) <- NULL
colnames(df2) <- c("mutation", "distance")# unique_id # distance # unique_id_that_it_is_close_to
fin_df <- df2 %>%
dplyr::mutate(start_mut = word(mutation, sep = "\\.", 1)) %>%
dplyr::mutate(stop_mut = word(mutation, sep = "\\.", 2)) %>%
dplyr::select(-mutation)
head(fin_df)
library("tidyverse")
# Read in the data
dat <- read_csv("~/Downloads/serina_test.csv")
nummuts <- length(dat$unique_id) # num uniq mutations
# Set up empty matrix
mat <- matrix(nrow = nummuts, ncol = nummuts)
# Populate matrix
for(i in 1:nummuts) {
for(j in 1:nummuts) {
mat[i,j] <- abs(dat$position[i] - dat$position[j])
}
}
colnames(mat) <- dat$unique_id
rownames(mat) <- dat$unique_id
# Set lower triangle of matrix to 0
mat[lower.tri(mat)] <- 0
distan <- apply(mat, 2, find_close)
# Function to find close mutations
find_close <- function(x) {
x[x > 0 & x < 10]
}
distan <- apply(mat, 2, find_close)
head(distan)
distan[[1]]
distan[[1]] <- c(3, 4, 3)
orig_mut <- names(unlist(distan))
df <- do.call("rbind", distan)
head(df)
distan
distan[[1]]
# Function to find close mutations
find_close <- function(x) {
x[x > 0 & x < 100]
}
distan <- apply(mat, 2, find_close)
orig_mut <- names(unlist(distan))
df <- do.call("rbind", distan)
head(df)
df2 <- data.frame(cbind(orig_mut, df))
rownames(df2) <- NULL
colnames(df2) <- c("mutation", "distance")
head(df2)
library("tidyverse")
# Read in the data
dat <- read_csv("~/Downloads/serina_test.csv")
nummuts <- length(dat$unique_id) # num uniq mutations
# Set up empty matrix
mat <- matrix(nrow = nummuts, ncol = nummuts)
# Populate matrix
for(i in 1:nummuts) {
for(j in 1:nummuts) {
mat[i,j] <- abs(dat$position[i] - dat$position[j])
}
}
colnames(mat) <- dat$unique_id
rownames(mat) <- dat$unique_id
# Set lower triangle of matrix to 0
mat[lower.tri(mat)] <- 0
# Function to find close mutations
find_close <- function(x) {
x[x > 0 & x < 100][1]
}
distan <- apply(mat, 2, find_close)
orig_mut <- names(unlist(distan))
df <- do.call("rbind", distan)
# Function to find close mutations
find_close <- function(x) {
val <- x[x > 0 & x < 100]
return(val[1])
}
distan <- apply(mat, 2, find_close)
orig_mut <- names(unlist(distan))
df <- do.call("rbind", distan)
# Read in the data
dat <- read_csv("~/Downloads/serina_test.csv")
nummuts <- length(dat$unique_id) # num uniq mutations
# Set up empty matrix
mat <- matrix(nrow = nummuts, ncol = nummuts)
# Populate matrix
for(i in 1:nummuts) {
for(j in 1:nummuts) {
mat[i,j] <- abs(dat$position[i] - dat$position[j])
}
}
colnames(mat) <- dat$unique_id
rownames(mat) <- dat$unique_id
# Set lower triangle of matrix to 0
mat[lower.tri(mat)] <- 0
# Function to find close mutations
find_close <- function(x) {
val <- x[x > 0 & x < 100]
return(val[1])
}
distan <- apply(mat, 2, find_close)
orig_mut <- names(unlist(distan))
df <- do.call("rbind", distan)
head(distan)
# Function to find close mutations
find_close <- function(x) {
val <- x[x > 0 & x < 100]
return(val[1])
}
distan <- apply(mat, 2, find_close)
# Read in the data
dat <- read_csv("~/Downloads/serina_test.csv")
# Read in the data
dat <- read_csv("~/Downloads/serina_test.csv")
nummuts <- length(dat$unique_id) # num uniq mutations
# Set up empty matrix
mat <- matrix(nrow = nummuts, ncol = nummuts)
# Populate matrix
for(i in 1:nummuts) {
for(j in 1:nummuts) {
mat[i,j] <- abs(dat$position[i] - dat$position[j])
}
}
colnames(mat) <- dat$unique_id
rownames(mat) <- dat$unique_id
# Set lower triangle of matrix to 0
mat[lower.tri(mat)] <- 0
# Function to find close mutations
find_close <- function(x) {
val <- x[x > 0 & x < 100]
return(val[1])
}
distan <- apply(mat, 2, find_close)
orig_mut <- names(unlist(distan))
df <- do.call("rbind", distan)
head(df)
# Function to find close mutations
find_close <- function(x) {
}
# Function to find close mutations
find_close <- function(x) {
x[grep("[^0-9]", x)]
}
distan <- apply(mat, 2, find_close)
orig_mut <- names(unlist(distan))
df <- do.call("rbind", distan)
# Populate matrix
for(i in 1:nummuts) {
for(j in 1:nummuts) {
mat[i,j] <- abs(dat$position[i] - dat$position[j])
}
}
colnames(mat) <- dat$unique_id
rownames(mat) <- dat$unique_id
# Set lower triangle of matrix to 0
mat[lower.tri(mat)] <- 0
# Function to find close mutations
find_close <- function(x) {
x[grep("[^0-9]", x)]
}
distan <- apply(mat, 2, find_close)
orig_mut <- names(unlist(distan))
head(distan)
# Read in the data
dat <- read_csv("~/Downloads/serina_test.csv")
nummuts <- length(dat$unique_id) # num uniq mutations
# Set up empty matrix
mat <- matrix(nrow = nummuts, ncol = nummuts)
# Populate matrix
for(i in 1:nummuts) {
for(j in 1:nummuts) {
mat[i,j] <- abs(dat$position[i] - dat$position[j])
}
}
colnames(mat) <- dat$unique_id
rownames(mat) <- dat$unique_id
# Set lower triangle of matrix to 0
mat[lower.tri(mat)] <- 0
# Function to find close mutations
find_close <- function(x) {
x[grep("[^0-9]", x)]
}
# Function to find close mutations
find_close <- function(x) {
x[grep("[^0-9]", x)]
}
distan <- apply(mat, 2, find_close)
head(distan)
# Function to find close mutations
find_close <- function(x) {
#x[grep("[^0-9]", x)]
x[x > 0 & x < 10]
}
distan <- apply(mat, 2, find_close)
head(distan)
orig_mut <- names(unlist(distan))
# Function to find close mutations
find_close <- function(x) {
#x[grep("[^0-9]", x)]
x[x > 0 & x < 100]
}
# Function to find close mutations
find_close <- function(x) {
#x[grep("[^0-9]", x)]
x[x > 0 & x < 100]
}
distan <- apply(mat, 2, find_close)
head(distan)
orig_mut <- names(unlist(distan))
orig_mut <- names(unlist(distan))
df <- do.call("rbind", distan)
head(df)
#df <- do.call("rbind", distan)
df <- data.table::rbindlinst(distan)
head(df)
#df <- do.call("rbind", distan)
df <- data.table::rbindlist(distan)
head(df)
distan <- apply(mat, 2, find_close)
orig_mut <- names(unlist(distan))
class(distan)
df <- data.table::rbindlist(distan, fill = T)
class(distan)
distan[[1]]
df2 <- dplyr::bind_rows(distan)
#df <- data.table::rbindlist(distan, fill = T)
df2 <- purrr::map_df(distan, ~as.data.frame(t(.distan),stringsAsFactors = FALSE))
class(distan)
#df <- data.table::rbindlist(distan, fill = T)
df2 <- purrr::map_df(x, ~as.data.frame(t(.x),stringsAsFactors = FALSE))
#df <- data.table::rbindlist(distan, fill = T)
df2 <- purrr::map_df(distan, ~as.data.frame(t(.x),stringsAsFactors = FALSE))
head(df2)
# Function to find close mutations
find_close <- function(x) {
#x[grep("[^0-9]", x)]
x[x > 0 & x < 10]
}
distan <- apply(mat, 2, find_close)
orig_mut <- names(unlist(distan))
df <- do.call("rbind", distan)
df2 <- dplyr::bind_rows(distan, fill = T)
#df <- data.table::rbindlist(distan, fill = T)
df_purr <- purrr::map_df(distan, ~as.data.frame(t(.x),stringsAsFactors = FALSE))
# Function to find close mutations
find_close <- function(x) {
#x[grep("[^0-9]", x)]
x[x > 0 & x < 10]
}
distan <- apply(mat, 2, find_close)
orig_mut <- names(unlist(distan))
#df <- data.table::rbindlist(distan, fill = T)
df_purr <- purrr::map_df(distan, ~as.data.frame(t(.x),stringsAsFactors = FALSE))
head(df_purr)
View(df_purr)
# Function to find close mutations
find_close <- function(x) {
#x[grep("[^0-9]", x)]
x[x > 0 & x < 100]
}
distan <- apply(mat, 2, find_close)
orig_mut <- names(unlist(distan))
#df <- data.table::rbindlist(distan, fill = T)
df_purr <- purrr::map_df(distan, ~as.data.frame(t(.x),stringsAsFactors = FALSE))
head(df_purr)
df2 <- data.frame(cbind(orig_mut, df))
View(df_purr)
#df <- data.table::rbindlist(distan, fill = T)
# df_purr <- purrr::map_df(distan, ~as.data.frame(t(.x),stringsAsFactors = FALSE))
df_res <- plyr::rbind.fill(lapply(distan, function(y){as.data.frame(t(y),
stringsAsFactors=FALSE)}))
head(df_res)
View(df_res)
# Function to find close mutations
find_close <- function(x) {
#x[grep("[^0-9]", x)]
x[x > 0 & x < 100]
}
distan <- apply(mat, 2, find_close)
orig_mut <- names(unlist(distan))
#df <- data.table::rbindlist(distan, fill = T)
# df_purr <- purrr::map_df(distan, ~as.data.frame(t(.x),stringsAsFactors = FALSE))
df_res <- plyr::rbind.fill(lapply(distan, function(y){as.data.frame(t(y),
stringsAsFactors=FALSE)}))
pdb_pull2
pdb_pull2
166/50064
0.0033 * 100
2000 - 1883
2020 - 1883
169 + 12
6.4/0.19
33.68/1e6
install.packages("rvg")
install.packages("rvg")
pacman::p_load("rvg")
---
title: "TARA Oceans Overview"
output:
flexdashboard::flex_dashboard:
theme: cosmo
vertical_layout: fill
runtime: shiny
---
install.packages("rvg")
pacman::p_load(rvg)
---
title: "TARA Oceans Overview"
output:
flexdashboard::flex_dashboard:
theme: cosmo
vertical_layout: fill
runtime: shiny
---
pacman::p_load("rvg")
pacman::p_load("OfficeR")
pacman::p_load("rvg")
install.packages(plotly)
install.packages("plotly")
library(tidyverse)
library(plotly)
library("reshsape2")
library("reshape2")
install.packages("reshape2")
library("reshape2")
melt
?melt
install.packages("remotes")
remotes::install_github("lmullen/mullenMisc")
length_of_degree <- function(degree, type = c("lat", "long")) {
type <- match.arg(type)
length_at_equator <- 110.5742727 # in kilometers
if (type == "long") {
cos(degree * (2 * pi) / 360) * length_at_equator
} else if (type == "lat") {
length_at_equator
}
}
jitter_latlong <- function(coord, type = c("lat", "long"), latitude, km = 1) {
type = match.arg(type)
if(missing(latitude) & type == "lat") {
latitude <- coord }
km_per_degree <- length_of_degree(latitude, type = type)
degree_per_km <- 1 / km_per_degree
coord + (runif(1, min = -1, max = 1) * degree_per_km * km)
}
jitter_latlong <- Vectorize(jitter_latlong,
vectorize.args = c("coord", "latitude"))
?jitter_latlong
??jitter_latlong
244/26000
library("xtable")
library("data.table")
library("shiny")
library("readxl")
## Read in the datasets
## This is the chemical compound dataset
tab <- read_excel("data/Compounds_complete.xlsx")
## Read in the datasets
## This is the chemical compound dataset
tab <- read_excel("data/Compounds_complete.xlsx", sheet = 1)
colnames(tab)
colnames(tab)[1:8] <- c("Compound", "Formula", "MW", "SMILES", "Synonyms", "CAS", "imgurl", "rxnurl")
install.packages("gggenes")
# install.packages("gggenes")
install.packages("genoPlotR")
tab$imgurl
library("xtable")
library("data.table")
library("shiny")
library("readxl")
# Challenge 3. Now try implementing eventReactive or observeEvent one one of the pages
# of your TARA oceans app. For example, to remove NAs each time a new variable is selected.
vec <- c(7,10,12,13,16)
scale(vec)
# Challenge 3. Now try implementing eventReactive or observeEvent one one of the pages
# of your TARA oceans app. For example, to remove NAs each time a new variable is selected.
vec <- c(7,10,0.4,6)
rescale(c(-10, -9, -5, 2, 6), to = c(0, 100))
scales::rescale(c(-10, -9, -5, 2, 6), to = c(0, 100))
scales::rescale(c(-10, -9, -5, 2, 6), to = c(4, 5))
# Install packages
pacman::p_load("tidyverse", "readxl", "DECIPHER")
x <- as.list(rnorm(10000))
names(x) <- paste("a", 1:length(x), sep = "")
x
x <- as.list(rnorm(10000))
names(x)
pos <- readAAStringSet("~/Downloads/rcsb_pdb_6EQO.fasta")
# Substr
pos_substr <- substr(pos, 110, 867)
# Substr
pos_substr <- AAStringSet(substr(pos, 110, 867))
# Install
pacman::p_load("DECIPHER", "Biostrings")
# Extract positions 110 through 867
pos <- readAAStringSet("~/Downloads/rcsb_pdb_6EQO.fasta")
# Substr
pos_substr <- AAStringSet(substr(pos, 110, 867))
pos_substr
width(pos)
writeXStringSet(pos_substr, "output/6EQO_subset_110_867_A_domain.fa")
writeXStringSet(pos_substr, "~/Downloads/6EQO_subset_110_867_A_domain.fa")
## Install packages
pacman::p_load("caret", "data.table", "Biostrings", "phangorn", "ape", "seqinr", "DECIPHER", "cowplot", "tidymodels", "ranger", "tree", "rsample", "tidyverse", "randomForest","gbm","nnet","e1071","svmpath","lars","glmnet","svmpath")
# Set working directory
setwd("~/Documents/Wageningen_UR/github/mibig_training_set_build_test/")
# Set seed
set.seed(20190403)
# Read in the data
rawdat <- read_csv("data/703_training_sqs_with_loop_extracted.csv")
# Read in the data
rawdat <- read_csv("data/703_training_sqs_with_loop_extracted.csv")
# Substr gene3
gene3 <- readAAStringSet("~/Downloads/gene3.faa")
substr2 <- AAStringSet(substr(gene3, 3100, 3585))
substr
substr2
writeXStringSet(substr2, "~/Downloads/gene3_trimmed.fa")
# What percentage have sequence-based prediction
pred <- read_excel("~/Documents/Wageningen_UR/manuscripts/AdenylPred/JBC_second_revision/Supplementary_Table_S3_edited_20200726.xlsx")
# Install
pacman::p_load("DECIPHER", "Biostrings", "readxl")
# What percentage have sequence-based prediction
pred <- read_excel("~/Documents/Wageningen_UR/manuscripts/AdenylPred/JBC_second_revision/Supplementary_Table_S3_edited_20200726.xlsx")
pred$`method of verification`
pred$`method of verification`
grep("prediction", pred$`method of verification`)
grep("prediction", pred$`assay type`)
grepl("prediction", pred$`assay type`)
table(grepl("prediction", pred$`assay type`))
table(grepl("prediction", pred$`assay type`))
table(grepl("purified", pred$`method of verification`))
860 * 2 * 12
table(grepl("prediction", pred$`assay type`))
# Install packages
pacman::p_load("Biostrings", "bio3d", "readxl", "tidyverse",
"janitor", "dplyr", "data.table")
#Set working directory
setwd("~/Documents/Wageningen_UR/github/mibig_training_set_build_test/")
# Read in the table
tab <- read_excel("output/20200421_JBC_MIBiG_validation_set_final.xlsx") %>%
dplyr::slice(1:41)
tab$acc
tabr <- AAStringSet(tab$aa_seq[tab$aa_seq != "NA"])
tabr
names(tabr) <- tab$acc[tab$aa_seq != "NA"]
sqs <- readAAStringSet("output/full_length_MIBiG_new_BGCs_Adomains_not_extracted.fasta")
tab$acc
mibig <- sqs[grep(paste0(tab$acc, collapse = "|"), names(sqs))]
names(mibig)
names(mibig) <- word(names(mibig), sep = "\\|", -1)
pdbs <- readAAStringSet("output/4_new_PDB_struct_seqs.fasta")
names(pdbs) <- paste0(names(pdbs), "_A")
rue <- readAAStringSet("data/Ruegeria_pomeroyi.fasta")
names(rue) <- "WP_011047771.1"
slividans <- readAAStringSet("data/20200420_S_lividans_seqs.fasta")
names(slividans) <- word(names(slividans), sep = " ", 1)
total <- AAStringSet(c(tabr, mibig, rue, pdbs, slividans))
total
dedup <- total[!duplicated(total)]
crys <- readAAStringSet("data/6EQO_subset_110_867_A_domain.fa")
gene3 <- readAAStringSet("data/gene3_trimmed.fa")
total <- AAStringSet(c(tabr, mibig, rue, pdbs, slividans, gene3, crys))
total
dedup <- total[!duplicated(total)]
# Install packages
pacman::p_load("Biostrings", "bio3d", "readxl", "tidyverse",
"janitor", "dplyr", "data.table")
#Set working directory
setwd("~/Documents/Wageningen_UR/github/mibig_training_set_build_test/")
# Read in the table
tab <- read_excel("output/20200421_JBC_MIBiG_validation_set_final.xlsx") %>%
dplyr::slice(1:41)
tab$acc
tabr <- AAStringSet(tab$aa_seq[tab$aa_seq != "NA"])
tabr
names(tabr) <- tab$acc[tab$aa_seq != "NA"]
sqs <- readAAStringSet("output/full_length_MIBiG_new_BGCs_Adomains_not_extracted.fasta")
tab$acc
mibig <- sqs[grep(paste0(tab$acc, collapse = "|"), names(sqs))]
names(mibig)
names(mibig) <- word(names(mibig), sep = "\\|", -1)
pdbs <- readAAStringSet("output/4_new_PDB_struct_seqs.fasta")
names(pdbs) <- paste0(names(pdbs), "_A")
rue <- readAAStringSet("data/Ruegeria_pomeroyi.fasta")
names(rue) <- "WP_011047771.1"
slividans <- readAAStringSet("data/20200420_S_lividans_seqs.fasta")
names(slividans) <- word(names(slividans), sep = " ", 1)
crys <- readAAStringSet("data/6EQO_subset_110_867_A_domain.fa")
gene3 <- readAAStringSet("data/gene3_trimmed.fa")
total <- AAStringSet(c(tabr, mibig, rue, pdbs, slividans, gene3, crys))
total
names(total)
dedup <- total[!duplicated(total)]
names(dedup)
rem <- dedup[-grep("ACY02013.1", names(dedup))]
rem
width(rem)
total <- AAStringSet(c(tabr, mibig, rue, pdbs, slividans, gene3, crys))
names(total)
#Set working directory
setwd("~/Documents/Wageningen_UR/github/mibig_training_set_build_test/")
# Validation set
valset <- read_excel("data/Supplementary_Table_S3_edited_20200726.xlsx")
valset
